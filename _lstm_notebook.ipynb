{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project - Inappropriate Language Classification - LSTM\n",
    "\n",
    "This notebook is separate from the rest as the embedding layers are directly integrated in the model. That is because the model adds it's own embeddings for the count vectorizer. Furthermore, the LSTM model has a set input size, as such the inputs will be troncated from the ? end / start ?\n",
    "\n",
    "This Jupyter Notebook contains the following features:\n",
    "1. Model Choice\n",
    "    1. Using the Base Embedding Layer\n",
    "        - Data Tockenisation\n",
    "        - Model building with embedding layer\n",
    "    2. Using the GloVe embeddings\n",
    "        - Data Embedding\n",
    "        - Model building without embedding layer\n",
    "2. Model Training\n",
    "3. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "max_input_size = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model choice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Default Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Tockenizer\n",
    "max_words = 10000 # Max number of words to use in the tockenizer\n",
    "\n",
    "from experiment_baseplate import get_text_data\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(get_text_data())\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Number of known words: \", len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_baseplate import load_split_data\n",
    "\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = load_split_data()\n",
    "\n",
    "#Tockenize data\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def post_process(X_values):\n",
    "    X_values = tokenizer.texts_to_sequences(X_values)\n",
    "    return pad_sequences(X_values, maxlen=max_input_size)\n",
    "\n",
    "X_train = post_process(X_train)\n",
    "X_test = post_process(X_test)\n",
    "X_validate = post_process(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define layers\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "embedding_dim = 200\n",
    "\n",
    "lstm_layers = [\n",
    "    tfl.Input(shape=(max_input_size,)),\n",
    "    tfl.Embedding(max_words, embedding_dim),\n",
    "    tfl.LSTM(64),\n",
    "    tfl.Dropout(0.2),\n",
    "    tfl.Dense(2, activation='softmax')\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If needed download weights\n",
    "'''\n",
    "from experiment_baseplate import get_glove_model\n",
    "\n",
    "get_glove_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe model\n",
      "Done loading GloVe model\n",
      "\n",
      "Embedding data\n",
      "Done Embedding data\n"
     ]
    }
   ],
   "source": [
    "from experiment_baseplate import get_split_glove_embedding\n",
    "\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = get_split_glove_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def post_process(X_values):\n",
    "    return np.array( pad_sequences(X_values, maxlen=max_input_size) )# , dtype=np.uint8)\n",
    "\n",
    "X_train = post_process(X_train)\n",
    "X_test = post_process(X_test)\n",
    "X_validate = post_process(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define layers\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "glove_embedding_dim = X_train.shape[2]\n",
    "\n",
    "lstm_layers = [\n",
    "    tfl.Input(shape=(max_input_size, glove_embedding_dim)),\n",
    "    tfl.LSTM(64),\n",
    "    tfl.Dropout(0.2),\n",
    "    tfl.Dense(2, activation='softmax')\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 200)]        0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                67840     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,970\n",
      "Trainable params: 67,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "if(len(lstm_layers) < 2):\n",
    "    print(\"Not enough layers in your model!\")\n",
    "    exit()\n",
    "\n",
    "for i in range(1, len(lstm_layers)):\n",
    "    lstm_layers[i] = lstm_layers[i](lstm_layers[i - 1])\n",
    "\n",
    "\n",
    "model = Model(inputs=lstm_layers[0], outputs=lstm_layers[-1])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4934/4934 [==============================] - 345s 69ms/step - loss: 0.3395 - accuracy: 0.8557 - val_loss: 0.3060 - val_accuracy: 0.8739\n",
      "Epoch 2/20\n",
      "4934/4934 [==============================] - 342s 69ms/step - loss: 0.2950 - accuracy: 0.8780 - val_loss: 0.2884 - val_accuracy: 0.8822\n",
      "Epoch 3/20\n",
      "4934/4934 [==============================] - 339s 69ms/step - loss: 0.2772 - accuracy: 0.8850 - val_loss: 0.2787 - val_accuracy: 0.8852\n",
      "Epoch 4/20\n",
      "4934/4934 [==============================] - 338s 69ms/step - loss: 0.2641 - accuracy: 0.8898 - val_loss: 0.2734 - val_accuracy: 0.8880\n",
      "Epoch 5/20\n",
      "4934/4934 [==============================] - 339s 69ms/step - loss: 0.2540 - accuracy: 0.8940 - val_loss: 0.2669 - val_accuracy: 0.8899\n",
      "Epoch 6/20\n",
      "4934/4934 [==============================] - 341s 69ms/step - loss: 0.2447 - accuracy: 0.8980 - val_loss: 0.2661 - val_accuracy: 0.8911\n",
      "Epoch 7/20\n",
      "4934/4934 [==============================] - 344s 70ms/step - loss: 0.2361 - accuracy: 0.9015 - val_loss: 0.2659 - val_accuracy: 0.8913\n",
      "Epoch 8/20\n",
      "4934/4934 [==============================] - 371s 75ms/step - loss: 0.2281 - accuracy: 0.9043 - val_loss: 0.2629 - val_accuracy: 0.8926\n",
      "Epoch 9/20\n",
      "4934/4934 [==============================] - 362s 73ms/step - loss: 0.2201 - accuracy: 0.9079 - val_loss: 0.2665 - val_accuracy: 0.8917\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d9a47768d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "# Early stopping regularization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_validate, y_validate), callbacks=[es])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3247/3247 [==============================] - 64s 20ms/step\n",
      "LSTM Model\n",
      "Test values\n",
      "\taccuracy : 0.8923022122956659 | precision : 0.8025218427323273 | recall : 0.6915935828877006 | f2 : 0.8908604519595025 | inf_time : 637437.5493386218 ns\n"
     ]
    }
   ],
   "source": [
    "from experiment_baseplate import score\n",
    "import time\n",
    "\n",
    "start = time.time_ns()\n",
    "X_test_predict = model.predict(X_test)\n",
    "test_time = time.time_ns() - start\n",
    "\n",
    "print(\"LSTM Model\")\n",
    "print(f\"Test values\\n\\t{score( X_test_predict , y_test)} | inf_time : {test_time / X_test.shape[0]} ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./saved/lstm/lstm_gl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bad_lang_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
