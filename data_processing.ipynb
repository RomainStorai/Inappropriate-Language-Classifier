{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "This notebook processes raw/downloaded data and compiles it into our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns=[\"text\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_column(df: pd.DataFrame, text_column = \"text\"):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"chars\"] = df[text_column].apply(len)\n",
    "    return df_copy[\"chars\"].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Raw Data\n",
    "This section loads the data from existing datasets and merges it into our dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hate Speech and Offensive Language\n",
    "- *Source*: https://github.com/t-davidson/hate-speech-and-offensive-language/raw/master/data/labeled_data.csv\n",
    "- *Datatype*: Tweets\n",
    "- *Description*: The text is classified as: hate-speech, offensive language, and neither\n",
    "- *Comments*: This dataset contains mainly hate speech data and isn't really defined on `neither` class\n",
    "- *Merge process*:\n",
    "    - `Inappropriate`: Offensive (1) or Hate Speech (0)\n",
    "    - `Appropriate`: Neither (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsaol = pd.read_csv(\"downloads/hsaol.csv\", sep=\",\")[[\"tweet\",\"class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsaol[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   24783 non-null  object\n",
      " 1   class   24783 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 387.4+ KB\n"
     ]
    }
   ],
   "source": [
    "hsaol.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24783.000000\n",
       "mean        85.436065\n",
       "std         41.548238\n",
       "min          5.000000\n",
       "25%         52.000000\n",
       "50%         81.000000\n",
       "75%        119.000000\n",
       "max        754.000000\n",
       "Name: chars, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_text_column(hsaol, \"tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_9728\\2866594782.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  hsaol[\"tweet\"] = hsaol[\"tweet\"].str.replace(\"^!*\", \"\")\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_9728\\2866594782.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  hsaol[\"tweet\"] = hsaol[\"tweet\"].str.replace(\"\\sRT\\s@.*:\", \" \")\n"
     ]
    }
   ],
   "source": [
    "hsaol[\"tweet\"] = hsaol[\"tweet\"].str.replace(\"^!*\", \"\")\n",
    "hsaol[\"tweet\"] = hsaol[\"tweet\"].str.replace(\"\\sRT\\s@.*:\", \" \")\n",
    "hsaol[\"inappro\"] = (hsaol[\"class\"] < 2).astype(int)\n",
    "\n",
    "hsaol = hsaol[[\"tweet\", \"inappro\"]].rename(columns={'tweet': 'text', 'inappro': 'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, hsaol], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Measuring Hate Speech\n",
    "- *Source*: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speechv\n",
    "- *Datatype*: Social media comments (Twitter, Reddit, Youtube)\n",
    "- *Description*: 10 ordinal labels (sentiment, (dis)respect, insult, humiliation, inferior status, violence, dehumanization, genocide, attack/defense, hate speech), which are debiased and aggregated into a continuous hate speech severity score (hate_speech_score)\n",
    "- *Comments*: This dataset contains mainly hate speech data (targeting class of individuals, not individuals directly)\n",
    "- *Merge process*:\n",
    "    - `Inappropriate`: `hate_speech_score` > 0.5\n",
    "    - `Appropriate`: `hate_speech_score` <= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "measuringhatespeech = pd.read_csv(\"downloads/measuring_hate_speech.csv\", sep=\",\")[[\"text\", \"hate_speech_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    135556.000000\n",
       "mean         -0.567428\n",
       "std           2.380003\n",
       "min          -8.340000\n",
       "25%          -2.330000\n",
       "50%          -0.340000\n",
       "75%           1.410000\n",
       "max           6.300000\n",
       "Name: hate_speech_score, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measuringhatespeech[\"hate_speech_score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135556 entries, 0 to 135555\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   text               135556 non-null  object \n",
      " 1   hate_speech_score  135556 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "measuringhatespeech.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    135556.000000\n",
       "mean        151.240742\n",
       "std         119.987785\n",
       "min           7.000000\n",
       "25%          60.000000\n",
       "50%         115.000000\n",
       "75%         209.000000\n",
       "max         603.000000\n",
       "Name: chars, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_text_column(measuringhatespeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "measuringhatespeech[\"inappro\"] = (measuringhatespeech[\"hate_speech_score\"] > 0.5).astype(int)\n",
    "\n",
    "measuringhatespeech = measuringhatespeech[[\"text\", \"inappro\"]].rename(columns={'inappro': 'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    86508\n",
       "1    49048\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measuringhatespeech[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, measuringhatespeech], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Insults Dataset\n",
    "- *Source*: https://www.kaggle.com/competitions/detecting-insults-in-social-commentary/\n",
    "- *Datatype*: Comments\n",
    "- *Description*: The label is either 0 meaning a neutral comment, or 1 meaning an insulting comment\n",
    "- *Comments*: This dataset does not contain particular hate speech, but aims individual\n",
    "- *Merge process*:\n",
    "    - `Inappropriate`: `Insult` == 1\n",
    "    - `Appropriate`: `Insult` == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "insults_test = pd.read_csv(\"downloads/insults/test_with_solutions.csv\", sep=\",\")[[\"Comment\", \"Insult\"]]\n",
    "insults_train = pd.read_csv(\"downloads/insults/train.csv\", sep=\",\")[[\"Comment\", \"Insult\"]]\n",
    "insults = pd.concat([insults_train, insults_test], ignore_index=True)\n",
    "\n",
    "insults = insults.rename(columns={\"Comment\": \"text\", \"Insult\": \"class\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4852\n",
       "1    1742\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insults[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6594 entries, 0 to 6593\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    6594 non-null   object\n",
      " 1   class   6594 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 103.2+ KB\n"
     ]
    }
   ],
   "source": [
    "insults.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     6594.000000\n",
       "mean       196.484835\n",
       "std        466.801387\n",
       "min          6.000000\n",
       "25%         55.000000\n",
       "50%        102.000000\n",
       "75%        204.000000\n",
       "max      20030.000000\n",
       "Name: chars, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_text_column(insults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, insults], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Jigsaw Dataset\n",
    "- *Source*: https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/ \n",
    "- *Datatype*: Wikipedia Comments and Chats\n",
    "- *Description*: You are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are: toxic, severe_toxic, obscene, threat, insult, identity_hate\n",
    "- *Comments*: \n",
    "- *Merge process*:\n",
    "    - `Inappropriate`: one of the class mentionned above\n",
    "    - `Appropriate`: none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 153164 entries, 0 to 153163\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             153164 non-null  object\n",
      " 1   comment_text   153164 non-null  object\n",
      " 2   toxic          153164 non-null  int64 \n",
      " 3   severe_toxic   153164 non-null  int64 \n",
      " 4   obscene        153164 non-null  int64 \n",
      " 5   threat         153164 non-null  int64 \n",
      " 6   insult         153164 non-null  int64 \n",
      " 7   identity_hate  153164 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "jigsaw_test_labels = pd.read_csv(\"downloads/jigsaw/test_labels.csv\", sep=\",\")\n",
    "jigsaw_test = pd.read_csv(\"downloads/jigsaw/test.csv\", sep=',')\n",
    "jigsaw_test = jigsaw_test.merge(jigsaw_test_labels, on=\"id\")\n",
    "jigsaw_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312735 entries, 0 to 312734\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   comment_text   312735 non-null  object\n",
      " 1   toxic          312735 non-null  int64 \n",
      " 2   severe_toxic   312735 non-null  int64 \n",
      " 3   obscene        312735 non-null  int64 \n",
      " 4   threat         312735 non-null  int64 \n",
      " 5   insult         312735 non-null  int64 \n",
      " 6   identity_hate  312735 non-null  int64 \n",
      " 7   id             153164 non-null  object\n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 19.1+ MB\n"
     ]
    }
   ],
   "source": [
    "jigsaw_train = pd.read_csv(\"downloads/jigsaw/train.csv\", sep=\",\")[[\"comment_text\",\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]]\n",
    "jigsaw = pd.concat([jigsaw_train, jigsaw_test], ignore_index=True)\n",
    "jigsaw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jigsaw[\"class\"] = jigsaw.apply(lambda x: 1 if x['toxic'] == 1 or x['severe_toxic'] == 1 or x['obscene'] == 1 or x['threat'] == 1 or x['insult'] == 1 or x['identity_hate'] == 1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    290267\n",
       "1     22468\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jigsaw[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jigsaw = jigsaw[[\"comment_text\", \"class\"]].rename(columns={\"comment_text\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    312735.000000\n",
       "mean        379.773262\n",
       "std         591.767791\n",
       "min           1.000000\n",
       "25%          87.000000\n",
       "50%         193.000000\n",
       "75%         414.000000\n",
       "max        5000.000000\n",
       "Name: chars, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_text_column(jigsaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312735 entries, 0 to 312734\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    312735 non-null  object\n",
      " 1   class   312735 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "jigsaw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, jigsaw], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Jibes and Delight\n",
    "- *Source*: https://aclanthology.org/2021.woah-1.14.pdf\n",
    "- *Datatype*: Reddit Comments\n",
    "- *Description*: The texts are preprocessed and fetched from different reddit channels to classify them.\n",
    "- *Comments*: Individual targeting\n",
    "- *Merge process*:\n",
    "    - `Inappropriate`: `Insulting`\n",
    "    - `Appropriate`: none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructJibesFile(data_type):\n",
    "    data = {\"text\": [], \"class\": []}\n",
    "    for i in [0, 1]:\n",
    "        with open(f\"downloads/jibesanddelights/comment.{data_type}.{i}.txt\") as f:\n",
    "            for line in f.readlines():\n",
    "                data[\"text\"].append(line)\n",
    "                data[\"class\"].append(i)\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "jad_dev = constructJibesFile(\"dev\")\n",
    "jad_test = constructJibesFile(\"test\")\n",
    "jad_train = constructJibesFile(\"train\")\n",
    "\n",
    "jad = pd.concat([jad_dev, jad_test, jad_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119261 entries, 0 to 119260\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    119261 non-null  object\n",
      " 1   class   119261 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "jad.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    68159\n",
       "1    51102\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jad[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    119261.000000\n",
       "mean         79.466515\n",
       "std          48.829422\n",
       "min           8.000000\n",
       "25%          49.000000\n",
       "50%          69.000000\n",
       "75%          96.000000\n",
       "max        2073.000000\n",
       "Name: chars, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_text_column(jad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, jad], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "As the data is collected from different sources and media sources, we will try to make it more uniform.\n",
    "\n",
    "Processes applied:\n",
    "- Making all text lowercased\n",
    "- Removing all stop words\n",
    "- Lemmatizing all words (putting the words to there basic form)\n",
    "- Try removing no english sentences\n",
    "- Removing sentences over 5000 characters (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text: str):\n",
    "    text = text.lower().removeprefix(\"\\\"\").removesuffix(\"\\\"\")\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 598929 entries, 0 to 598928\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    598929 non-null  object\n",
      " 1   class   598929 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    453949\n",
       "1    144980\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    598929.000000\n",
       "mean        254.006525\n",
       "std         454.971904\n",
       "min           1.000000\n",
       "25%          62.000000\n",
       "50%         118.000000\n",
       "75%         260.000000\n",
       "max       20030.000000\n",
       "Name: chars, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_text_column(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(mininterval=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598929/598929 [1:33:55<00:00, 106.27it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset[\"cleaned\"] = dataset.progress_apply(lambda x : clean_text(x[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing: 598929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598929/598929 [00:00<00:00, 855458.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing: 598921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove text with less than one word\n",
    "print(f\"Before removing: {len(dataset)}\")\n",
    "dataset = dataset[dataset[\"cleaned\"].progress_apply(lambda x: len(x) >= 1)]\n",
    "print(f\"After removing: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing non-english text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 598921/598921 [1:25:56<00:00, 116.15it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing non-english text\")\n",
    "def detect_language(s: str) -> bool:\n",
    "    try:\n",
    "        return detect(s) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "dataset_en = dataset[dataset[\"cleaned\"].progress_apply(lambda x: detect_language(str(x)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    402503\n",
       "1    116877\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    519380.000000\n",
       "mean        189.794364\n",
       "std         322.538216\n",
       "min           4.000000\n",
       "25%          50.000000\n",
       "50%          94.000000\n",
       "75%         198.000000\n",
       "max       14602.000000\n",
       "Name: chars, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_text_column(dataset, \"cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[[\"cleaned\", \"class\"]].rename(columns={\"cleaned\": \"text\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset[\"text\"].apply(lambda x: len(x) < 5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text:\t519369\n",
      "Class 0:\t402496\t\t(77.49711669352618%)\n",
      "Class 1:\t116873\t\t(22.502883306473816%)\n"
     ]
    }
   ],
   "source": [
    "#Display dataset info\n",
    "total = len(dataset)\n",
    "app = len(dataset[(dataset[\"class\"] == 0)])\n",
    "inapp = len(dataset[(dataset[\"class\"] == 1)])\n",
    "print(f\"Total text:\\t{total}\\nClass 0:\\t{app}\\t\\t({app / total * 100}%)\\nClass 1:\\t{inapp}\\t\\t({inapp / total * 100}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    519369.000000\n",
       "mean        189.667785\n",
       "std         321.104075\n",
       "min           4.000000\n",
       "25%          50.000000\n",
       "50%          94.000000\n",
       "75%         198.000000\n",
       "max        4999.000000\n",
       "Name: chars, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_text_column(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 519369 entries, 0 to 598928\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    519369 non-null  object\n",
      " 1   class   519369 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset[\"text\"].apply(lambda x: len(x) > 5000)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataset(dataframe: pd.DataFrame, total_length):\n",
    "    total = len(dataframe)\n",
    "    app = len(dataframe[(dataframe[\"class\"] == 0)])\n",
    "    inapp = len(dataframe[(dataframe[\"class\"] == 1)])\n",
    "    return f\"\\n\\t{total}\\t\\t{int(total/total_length*100)}%\\n\\t\\t({int(app / total * 100)}%\\t{int(inapp / total * 100)}%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  \n",
      "\t315776\t\t60%\n",
      "\t\t(77%\t22%)\n",
      "Test:  \n",
      "\t103874\t\t20%\n",
      "\t\t(77%\t22%)\n",
      "Validation:  \n",
      "\t99719\t\t19%\n",
      "\t\t(77%\t22%)\n"
     ]
    }
   ],
   "source": [
    "# Split Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['text'], dataset['class'], test_size=0.2, stratify=dataset['class'])\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.24, stratify=y_train)\n",
    "\n",
    "train = pd.DataFrame({\"text\": X_train, \"class\": y_train})\n",
    "test = pd.DataFrame({\"text\": X_test, \"class\": y_test})\n",
    "validate = pd.DataFrame({\"text\": X_validation, \"class\": y_validation})\n",
    "\n",
    "\n",
    "print(\"Train: \", describe_dataset(train, total))\n",
    "print(\"Test: \", describe_dataset(test, total))\n",
    "print(\"Validation: \", describe_dataset(validate, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset\n",
    "train.to_csv(\"data/train.csv\")\n",
    "validate.to_csv(\"data/validate.csv\")\n",
    "test.to_csv(\"data/test.csv\")\n",
    "dataset.to_csv(\"data/full.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
